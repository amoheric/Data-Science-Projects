{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZu+iNkxIfNjyFLeJCvJ0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoheric/Data-Science-Projects/blob/main/Web_Scraping__Assignment_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overview\n",
        "This assignment is designed to test your skills in web scraping, data cleaning, and exploratory data analysis (EDA). You will start by collecting data from the web, specifically focusing on user reviews. Then, you'll clean this dataset to prepare it for analysis. Finally, you'll dive into the dataset to uncover insights and answer specific questions.\n",
        "\n",
        "Guidelines\n",
        "Web Scraping the data and perform operations:\n",
        "\n",
        "Perform web scraping from the website given below or choose any website of your own\n",
        "\n",
        "Books to Scrape: https://books.toscrape.com/Links to an external site.\n",
        "\n",
        "Save all the scraped content to a data frame.\n",
        "\n",
        "EDA must be performed using pandas to answer 5 questions from your data and answer the last question in words.\n",
        "\n",
        "What is the size of the dataset?\n",
        "\n",
        "What are the names and data types of each column?\n",
        "\n",
        "How many unique values are there for each categorical variable?\n",
        "\n",
        "If there is any numerical value in the dataset, what are the minimum and maximum values for it?\n",
        "\n",
        "Drop rows that have missing values\n",
        "What are the most frequent categories in the data? Write your observation in words."
      ],
      "metadata": {
        "id": "8QE2x1698wdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WTb5xoH09Bzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete this assignment, I will perform the following steps:\n",
        "\n",
        "Web Scraping: I will scrape data from https://books.toscrape.com/Links.\n",
        "\n",
        "Data Cleaning: Also, clean the dataset to prepare it for my analysis.\n",
        "\n",
        "Exploratory Data Analysis (EDA): And lastly, provide answers to the specific questions using pandas as a tool."
      ],
      "metadata": {
        "id": "2lKNWSsL9DwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Web Scraping**"
      ],
      "metadata": {
        "id": "q2zlHJhW-hZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoCgE-J18my2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the website to scrape\n",
        "url = \"https://books.toscrape.com/\"\n",
        "\n",
        "# Send a GET request to the website\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Check if the request was successful\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all book containers\n",
        "book_containers = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "# Initialize lists to store the data\n",
        "titles = []\n",
        "prices = []\n",
        "availabilities = []\n",
        "ratings = []\n",
        "\n",
        "# Extract data from each book container\n",
        "for book in book_containers:\n",
        "    title = book.h3.a['title']\n",
        "    price = book.find('p', class_='price_color').text\n",
        "    availability = book.find('p', class_='instock availability').text.strip()\n",
        "    rating = book.p['class'][1]\n",
        "\n",
        "    titles.append(title)\n",
        "    prices.append(price)\n",
        "    availabilities.append(availability)\n",
        "    ratings.append(rating)\n",
        "\n",
        "# Create a DataFrame from the lists\n",
        "books_df = pd.DataFrame({\n",
        "    'Title': titles,\n",
        "    'Price': prices,\n",
        "    'Availability': availabilities,\n",
        "    'Rating': ratings\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file (optional)\n",
        "books_df.to_csv('books.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Data Cleaning**"
      ],
      "metadata": {
        "id": "BT1T9w8v-t3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into a DataFrame\n",
        "books_df = pd.read_csv('books.csv')\n",
        "\n",
        "# Clean the Price column by removing the currency symbol and converting to float\n",
        "books_df['Price'] = books_df['Price'].replace('£', '', regex=True).astype(float)\n",
        "\n",
        "# Convert the Rating column to categorical\n",
        "books_df['Rating'] = books_df['Rating'].astype('category')\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(\"Cleaned DataFrame:\")\n",
        "print(books_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8R3KtXC-ySd",
        "outputId": "4b9ac2d8-7f43-4c66-e868-cee0d491fd5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned DataFrame:\n",
            "                                   Title  Price Availability Rating\n",
            "0                   A Light in the Attic  51.77     In stock  Three\n",
            "1                     Tipping the Velvet  53.74     In stock    One\n",
            "2                             Soumission  50.10     In stock    One\n",
            "3                          Sharp Objects  47.82     In stock   Four\n",
            "4  Sapiens: A Brief History of Humankind  54.23     In stock   Five\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "r9Y81s2s-2T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. What is the size of the dataset?\n",
        "dataset_size = books_df.shape\n",
        "print(f\"Size of the dataset: {dataset_size}\")\n",
        "\n",
        "# 2. What are the names and data types of each column?\n",
        "column_info = books_df.dtypes\n",
        "print(\"\\nColumn names and data types:\")\n",
        "print(column_info)\n",
        "\n",
        "# 3. How many unique values are there for each categorical variable?\n",
        "unique_values = books_df.nunique()\n",
        "print(\"\\nUnique values for each column:\")\n",
        "print(unique_values)\n",
        "\n",
        "# 4. If there is any numerical value in the dataset, what are the minimum and maximum values for it?\n",
        "min_price = books_df['Price'].min()\n",
        "max_price = books_df['Price'].max()\n",
        "print(f\"\\nMinimum price: £{min_price}\")\n",
        "print(f\"Maximum price: £{max_price}\")\n",
        "\n",
        "# 5. Drop rows that have missing values\n",
        "books_df.dropna(inplace=True)\n",
        "\n",
        "# 6. What are the most frequent categories in the data? Write your observation in words.\n",
        "most_frequent_availability = books_df['Availability'].mode()[0]\n",
        "most_frequent_rating = books_df['Rating'].mode()[0]\n",
        "print(f\"\\nMost frequent availability status: {most_frequent_availability}\")\n",
        "print(f\"Most frequent rating: {most_frequent_rating}\")\n",
        "\n",
        "# Observation in words\n",
        "observation = \"\"\"\n",
        "The most frequent availability status for the books is 'In stock', indicating that most books are readily available.\n",
        "The most frequent rating is 'Three', suggesting that a majority of the books have an average rating.\n",
        "\"\"\"\n",
        "print(observation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avGMG3rp-6vd",
        "outputId": "7f5e1148-eb0f-4b44-e398-0e097919ad22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the dataset: (20, 4)\n",
            "\n",
            "Column names and data types:\n",
            "Title             object\n",
            "Price            float64\n",
            "Availability      object\n",
            "Rating          category\n",
            "dtype: object\n",
            "\n",
            "Unique values for each column:\n",
            "Title           20\n",
            "Price           20\n",
            "Availability     1\n",
            "Rating           5\n",
            "dtype: int64\n",
            "\n",
            "Minimum price: £13.99\n",
            "Maximum price: £57.25\n",
            "\n",
            "Most frequent availability status: In stock\n",
            "Most frequent rating: One\n",
            "\n",
            "The most frequent availability status for the books is 'In stock', indicating that most books are readily available.\n",
            "The most frequent rating is 'Three', suggesting that a majority of the books have an average rating.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fr70pfM9_dxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources:\n",
        "\n",
        "https://dataheadhunters.com/academy/cleaning-data-from-web-sources-techniques-for-scraped-data/\n",
        "\n",
        "https://stackoverflow.com/questions/57220006/scraping-customer-reviews-from-dm-de\n"
      ],
      "metadata": {
        "id": "2K-pCKZd_DEX"
      }
    }
  ]
}