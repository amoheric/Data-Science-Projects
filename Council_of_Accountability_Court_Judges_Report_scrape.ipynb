{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/0/tqHdVfTtw9smfK1kEV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoheric/Data-Science-Projects/blob/main/Council_of_Accountability_Court_Judges_Report_scrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Python Libraries\n"
      ],
      "metadata": {
        "id": "RNIVgecO0WIk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "gwyPEKWN0Pku"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Getting the HTML Content"
      ],
      "metadata": {
        "id": "fTT0c0lF0mc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the HTML content of a given URL\n",
        "def get_html_content(url):\n",
        "    \"\"\"\n",
        "    Fetch the content of the provided URL.\n",
        "\n",
        "    Parameters:\n",
        "    url (str): The URL of the webpage to scrape.\n",
        "\n",
        "    Returns:\n",
        "    soup (BeautifulSoup): Parsed HTML content of the webpage.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    return soup"
      ],
      "metadata": {
        "id": "K360zSDo02V4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting Report Links From The Webpage"
      ],
      "metadata": {
        "id": "5Ie9TZh806mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract report links from the webpage\n",
        "def extract_report_links(soup):\n",
        "    \"\"\"\n",
        "    Extracts links to annual reports or other important documents from the webpage.\n",
        "\n",
        "    Parameters:\n",
        "    soup (BeautifulSoup): Parsed HTML content of the webpage.\n",
        "\n",
        "    Returns:\n",
        "    reports (list): A list of dictionaries containing report names and their URLs.\n",
        "    \"\"\"\n",
        "    reports = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "\n",
        "        # Example condition to identify report links (modify as needed)\n",
        "        if 'Annual Report' in link.text or 'Performance Metrics' in link.text:\n",
        "            reports.append({\n",
        "                'Report Name': link.text.strip(),\n",
        "                'URL': link['href']\n",
        "            })\n",
        "\n",
        "    return reports"
      ],
      "metadata": {
        "id": "o1JCbCJ41Qnb"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Getting The HTML Structure For Review"
      ],
      "metadata": {
        "id": "0OPfT8gc1PoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fetch HTML content\n",
        "def get_html_content(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for bad status codes\n",
        "        return BeautifulSoup(response.content, 'lxml')  # Or 'html.parser', 'html5lib'\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching URL {url}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "t2oIkgXo5us7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting Quantitative Data"
      ],
      "metadata": {
        "id": "yKAsQjem1Pe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract quantitative data from the reports\n",
        "def extract_quantitative_data(reports):\n",
        "    \"\"\"\n",
        "    Extracts quantitative data such as recidivism rates, completion rates, etc., from the reports.\n",
        "\n",
        "    Parameters:\n",
        "    reports (list): A list of dictionaries containing report names and their URLs.\n",
        "\n",
        "    Returns:\n",
        "    data (pd.DataFrame): DataFrame containing the extracted quantitative data.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for report in reports:\n",
        "        # Fetch the report content (this is a placeholder for actual logic)\n",
        "        report_content = get_html_content(report['URL'])\n",
        "\n",
        "\n",
        "        if report_content:\n",
        "            # Print content to verify it's being captured\n",
        "            print(f\"Scraping report: {report['Report Name']}\")\n",
        "            print(report_content.text[:500])  # Print first 500 characters to inspect\n",
        "\n",
        "\n",
        "        # Example extraction logic (modify based on actual data structure)\n",
        "        # Use regex or other parsing methods to extract numerical data\n",
        "        # For example, extracting recidivism rates\n",
        "        recidivism_rate = re.findall(r'Recidivism Rate: (\\d+)%', report_content.text)\n",
        "\n",
        "\n",
        "        if recidivism_rate:\n",
        "            data.append({\n",
        "                'Report Name': report['Report Name'],\n",
        "                'Recidivism Rate (%)': recidivism_rate[0]\n",
        "            })\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"No data found for {report['Report Name']} at {report['URL']}\")\n",
        "\n",
        "\n",
        "    else:\n",
        "            print(f\"Skipping {report['Report Name']} due to error fetching content.\")\n",
        "\n",
        "    # Convert list of dictionaries to DataFrame for further analysis\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "DqG_SeBj1RWZ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting Qualitative Data"
      ],
      "metadata": {
        "id": "2KaE29y51Pv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract qualitative data (e.g., descriptions, feedback)\n",
        "def extract_qualitative_data(reports):\n",
        "    \"\"\"\n",
        "    Extracts qualitative data such as descriptions, feedback, and case studies from the reports.\n",
        "\n",
        "    Parameters:\n",
        "    reports (list): A list of dictionaries containing report names and their URLs.\n",
        "\n",
        "    Returns:\n",
        "    qualitative_data (list): A list of extracted qualitative data.\n",
        "    \"\"\"\n",
        "    qualitative_data = []\n",
        "    for report in reports:\n",
        "        # Fetch the report content\n",
        "        report_content = get_html_content(report['URL'])\n",
        "\n",
        "\n",
        "        # Example extraction logic (modify based on actual content)\n",
        "        # Extract paragraphs containing case studies or feedback\n",
        "        paragraphs = report_content.find_all('p')\n",
        "        for para in paragraphs:\n",
        "\n",
        "            if 'Case Study' in para.text or 'Feedback' in para.text:\n",
        "                qualitative_data.append(para.text.strip())\n",
        "\n",
        "    return qualitative_data"
      ],
      "metadata": {
        "id": "v_9RmufV1TCf"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing The Extracted Quantitative Data"
      ],
      "metadata": {
        "id": "meckTGFK1P1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to visualize the quantitative data\n",
        "def visualize_quantitative_data(df):\n",
        "    \"\"\"\n",
        "    Visualizes the extracted quantitative data using bar charts.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): DataFrame containing the extracted quantitative data.\n",
        "    \"\"\"\n",
        "   # Check if the DataFrame is empty\n",
        "    if df.empty:\n",
        "        print(\"No data available to visualize.\")\n",
        "        return\n",
        "\n",
        "    # Print the columns to verify the correct names\n",
        "    print(\"DataFrame columns:\", df.columns)\n",
        "\n",
        "    # Visualize the data if columns exist\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(df['Report Name'], df['Recidivism Rate (%)'].astype(int), color='blue')\n",
        "        plt.xlabel('Report')\n",
        "        plt.ylabel('Recidivism Rate (%)')\n",
        "        plt.title('Recidivism Rates by Report')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e} - Check if the column names match the expected format.\")"
      ],
      "metadata": {
        "id": "He-whPBC1VhL"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions To Run The Data"
      ],
      "metadata": {
        "id": "aZAOVKZ81P64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to run the data scraping and analysis\n",
        "def main():\n",
        "\n",
        "    # URL of the CACJ resources or reports page\n",
        "    url = 'https://cacj.georgia.gov/resources','https://cacj.georgia.gov/reports','https://cacj.georgia.gov/data-research','https://cacj.georgia.gov/fy2024-quarterly-data-collection-materials','https://cacj.georgia.gov/fy2023-quarterly-data-collection-materials','https://cacj.georgia.gov/fy2022-quarterly-data-collection-materials','https://cacj.georgia.gov/fy2021-quarterly-data-collection-materials','https://cacj.georgia.gov/fy2020-quarterly-data-collection-materials','https://cacj.georgia.gov/fy2019-quarterly-data-collection-materials','https://cacj.georgia.gov/treatment'\n",
        "\n",
        "    # Get the HTML content of the webpage\n",
        "    soup = get_html_content(url)\n",
        "\n",
        "\n",
        "    # Extract report links\n",
        "    reports = extract_report_links(soup)\n",
        "\n",
        "\n",
        "    # Extract quantitative data\n",
        "    quantitative_df = extract_quantitative_data(reports)\n",
        "\n",
        "\n",
        "    # Debugging: Check if quantitative_df is defined and its structure\n",
        "    print(quantitative_df.columns)\n",
        "    print(quantitative_df.head())\n",
        "\n",
        "\n",
        "    # Visualize quantitative data\n",
        "    visualize_quantitative_data(quantitative_df)\n",
        "\n",
        "\n",
        "    # Print qualitative data for review\n",
        "    qualitative_data = extract_qualitative_data(reports)\n",
        "    for i, data in enumerate(qualitative_data):\n",
        "        print(f\"Qualitative Data {i+1}: {data}\\n\")\n",
        "\n",
        "\n",
        "    # Optionally, save the data to CSV or JSON\n",
        "    quantitative_df.to_csv('quantitative_data.csv', index=False)\n",
        "    with open('qualitative_data.json', 'w') as f:\n",
        "        json.dump(qualitative_data, f, indent=4)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    reports = [\n",
        "        {'Report Name': 'Annual Report 2023', 'URL': 'https://online.pubhtml5.com/krpu/ryir/'},\n",
        "        {'Report Name': 'Annual Report 2022', 'URL': 'https://cacj.georgia.gov/document/document/fy22-cacj-statewide-report/download'},\n",
        "        {'Report Name': 'Annual Report 2021', 'URL': 'https://cacj.georgia.gov/document/document/fy21-cacj-statewide-report/download'},\n",
        "        {'Report Name': 'Annual Report 2020', 'URL': 'https://cacj.georgia.gov/document/document/fy20-cacj-statewide-report/download'},\n",
        "        {'Report Name': 'Annual Report 2019', 'URL': 'https://cacj.georgia.gov/document/data/fy19-cacj-statewide-report/download'}\n",
        "    ]\n",
        "\n",
        "    df = extract_quantitative_data(reports)\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"No data extracted.\")\n",
        "    else:\n",
        "        print(df)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAkLjAKb1T-F",
        "outputId": "1e66ed29-4ebe-47e0-f901-93dd692b159e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping report: Annual Report 2023\n",
            "\n",
            "\n",
            "FINAL_FY23 CACJ Annual Report _Published\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "No data found for Annual Report 2023 at https://online.pubhtml5.com/krpu/ryir/\n",
            "Scraping report: Annual Report 2022\n",
            "%âãÏÓ\n",
            "           \n",
            "<>/Filter/FlateDecode/ID[<194D99256300EA488357B6DEDE8B71D7><\n",
            "No data found for Annual Report 2022 at https://cacj.georgia.gov/document/document/fy22-cacj-statewide-report/download\n",
            "Scraping report: Annual Report 2021\n",
            "%âãÏÓ\n",
            "          \n",
            "<>/Filter/FlateDecode/ID[]/Index[1337 25]/Info 1336 0 R/Length 86/Prev 441957/Root 1338 0 R/Size 1362/Type/XRef/W[1 3 1]>>stream\n",
            "hÞbbd```b``¶‘s@$“5XÄÌ. ‘,Ÿ@$£X<\n",
            "No data found for Annual Report 2021 at https://cacj.georgia.gov/document/document/fy21-cacj-statewide-report/download\n",
            "Scraping report: Annual Report 2020\n",
            "%âãÏÓ\n",
            "<\n",
            "No data found for Annual Report 2020 at https://cacj.georgia.gov/document/document/fy20-cacj-statewide-report/download\n",
            "Scraping report: Annual Report 2019\n",
            "%âãÏÓ\n",
            "             \n",
            "<>/Filter/FlateDecode/ID[<\n",
            "No data found for Annual Report 2019 at https://cacj.georgia.gov/document/data/fy19-cacj-statewide-report/download\n",
            "Skipping Annual Report 2019 due to error fetching content.\n",
            "No data extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "print(df.head())  # Prints the first few rows of the DataFrame\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw84PGWI3xwV",
        "outputId": "4c5327f3-36de-436f-973e-cd278aeec773"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKcoc5PMCec1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}